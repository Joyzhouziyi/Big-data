<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Big data - An introduction</title>
    <link rel="stylesheet" href="style.css">
    <style>
        body{width:  800px;margin: 0 auto;}
    </style>
</head>
<body>
        <span id="topnav">
            <p>
                    <a href="#sec1">inreoduction</a>
                    <a href="#sec3">Definition</a>
                    <a href="#sec2">Characteristics</a>
            
                </p>
        </span>
        <span id="title">
        <h1>Big data An Introduction</h1>
        </span>
        <span id="topnov">
    </div>
    <img src="big data.jpg" alt="a graph about the big data">
    <div id = "sec1">
        <h2>Definition</h2>
            
            <p> <strong>Big data</strong> Big data can also =<a href="https://zh.m.wikipedia.org/zh-hk/%E5%A4%A7%E6%95%B8%E6%93%9A">big data</a> target="_blank">data set</a> be defined as large amounts of unstructured or <br>
                structured data from various sources. From an academic perspective, the emergence of big data has enabled novel research on a wide range of topics.</p>
            <p><a href="#sec1">Big data</a> consists of huge data sets ( English : Data set ) , the size of these data sets often exceeds the human ability to collect ( English : data acquisition ) , use ( English : data curation ) , manage and process in an acceptable time [16] ] . The size of big data changes frequently, and as of 2012 , single datasets range in size from a few terabytes (TB) to tens of terabytes (PB).
                In a 2001 study and related presentation [17] , Doug Laney , an analyst at the META Group (now Gartner), pointed out that the challenges and opportunities of data growth lie in three directions: : Volume ( Volume , data size), Velocity ( Velocity , speed of data input and output) and change ( Variety , diversity), collectively referred to as "3V" or "3Vs". Gartner and most companies in the big data industry continue to use 3V to describe big data [18] . Gartner revised the definition of big data in 2012: "Big data is a large volume, high speed, and/or changeable information assets, which require new processing methods to promote stronger decision-making capabilities, insight and optimization Dealing with [Original 1] [19] .‚Äù In addition, some organizations define the fourth V in addition to the 3V: veracity ( Veracity ) is the fourth characteristic [20] .
        
                Big data must be counted, compared, and analyzed by computer in order to obtain objective results. The United States started to work on big data in 2012, and Obama even invested 200 million U.S. dollars in the development of big data in the same year, emphasizing that big data will be the oil of the future.
        
                Data mining (data mining) is to discuss the methods used to analyze big data. <br>
        
                Big data requires special techniques to efficiently handle large volumes of data that tolerate elapsed time. Technologies for special big data, including massively parallel processing (MPP) databases, data mining, distributed file systems, distributed databases, cloud computing platforms, the Internet, and scalable storage systems.</p>
     </div>
    <div name="sec3">    
        <h2>Characteristics</h2>
   
        <div id="table">
            <h3>Table of content</h3>
            <ul>
                <li>volumn</li>
                <li>varitiety</li>
                <li>Velocity</li>
                <li>veracity</li>
                <li>value</li>
            </ul>
        </div>
        <p>Big data can be describe by the following characteristic</p>
        <h4>Valome</h4>
        <p>The quantity of generated and stored data. The size of the data determines the value and potential insight, and whether it can be considered big data or not. The size of big data is usually larger than terabytes and petabytes.[36]</p>
        <h4>Variety</h4>
        <p>The type and nature of the data. The earlier technologies like RDBMSs were capable to handle structured data efficiently and effectively. However, the change in type and nature from structured to semi-structured or unstructured challenged the existing tools and technologies. The big data technologies evolved with the prime intention to capture, store, and process the semi-structured and unstructured (variety) data generated with high speed (velocity), and huge in size (volume). Later, these tools and technologies were explored and used for handling structured data also but preferable for storage. Eventually, the processing of structured data was still kept as optional, either using big data or traditional RDBMSs. This helps in analyzing data towards effective usage of the hidden insights exposed from the data collected via social media, log files, sensors, etc. Big data draws from text, images, audio, video; plus it completes missing pieces through data fusion.</p>
        <h4>Velocity</h4>
        <p>The speed at which the data is generated and processed to meet the demands and challenges that lie in the path of growth and development. Big data is often available in real-time. Compared to small data, big data is produced more continually. Two kinds of velocity related to big data are the frequency of generation and the frequency of handling, recording, and publishing.</p>
        <h4>Veracity</h4>
        <p>The truthfulness or reliability of the data, which refers to the data quality and the data value.[38] Big data must not only be large in size, but also must be reliable in order to achieve value in the analysis of it. The data quality of captured data can vary greatly, affecting an accurate analysis.</p>
    </div>

    <a href="#">BACK TO THE TOP</a>
</body>
</html>